{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Jimmy went to Washington DC with Berlin Air\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity text: Jimmy          \n",
      "Entity Label: PERSON  \n",
      "Meaning: People, including fictional\n",
      "\n",
      "Entity text: Washington DC  \n",
      "Entity Label: GPE     \n",
      "Meaning: Countries, cities, states\n",
      "\n",
      "Entity text: Berlin Air     \n",
      "Entity Label: ORG     \n",
      "Meaning: Companies, agencies, institutions, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f\"Entity text: {ent.text:{15}}\")\n",
    "    print(f\"Entity Label: {ent.label_:{8}}\") \n",
    "    print(f\"Meaning: {spacy.explain(ent.label_)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jimmy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " went to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Washington DC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Berlin Air\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style=\"ent\",jupyter=True,options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.remove('no')\n",
    "stopwords.remove('against')\n",
    "stopwords.remove('below')\n",
    "stopwords.remove('cannot')\n",
    "stopwords.remove('more')\n",
    "stopwords.remove('much')\n",
    "stopwords.remove('about')\n",
    "stopwords.remove('above')\n",
    "stopwords.remove('almost')\n",
    "stopwords.remove('always')\n",
    "stopwords.remove(\"n't\")\n",
    "stopwords.remove('never')\n",
    "stopwords.remove('not')\n",
    "stopwords.remove('nâ€™t')\n",
    "stopwords.remove('often')\n",
    "stopwords.remove('because')\n",
    "stopwords.remove('do')\n",
    "stopwords.remove(\"will\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.add('i')\n",
    "stopwords.add(\"i'm\")\n",
    "stopwords.add(\"it\")\n",
    "stopwords.add(\"my\")\n",
    "stopwords.add(\"we\")\n",
    "stopwords.add(\"he\")\n",
    "stopwords.add(\"she\")\n",
    "stopwords.add(\"this\")\n",
    "stopwords.add(\"it\")\n",
    "stopwords.add(\"that\")\n",
    "stopwords.add(\"\\n\")\n",
    "stopwords.add(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = pd.read_csv('processed_data/restaurant_az_reviews.csv').drop(labels='Unnamed: 0', axis=1).head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_restaurants = pd.read_csv('processed_data/restaurants_az.csv').drop(labels='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ = pd.DataFrame(all_reviews.groupby('review_stars').count()[['business_id']].rename(columns={'review_stars': 'Stars', 'business_id': 'Restaurants'})).head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ.plot.bar(colormap='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(all_reviews['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['text'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = all_reviews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "start = time.time()\n",
    "A = reviews.apply(nlp)\n",
    "end   = time.time()\n",
    "print(f'Duration:   {end-start:{5}}')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1751.9552311897278*100000/60/100000/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "start = time.time()\n",
    "X = reviews.apply(word_tokenize)\n",
    "end   = time.time()\n",
    "print(f'Duration:   {end-start:{5}}')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(71.00524020195007*2/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagger\n",
    "start = time.time()\n",
    "X = pos_tag_sents( reviews.apply(word_tokenize).tolist(), lang='eng' )\n",
    "end   = time.time()\n",
    "print(f'Duration:   {end-start:{5}}')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many reviews we have of each star\n",
    "x = AZ.review_stars.value_counts().index\n",
    "y = Restaurant_reviews.review_stars.value_counts().values\n",
    "\n",
    "plot.figure(figsize=(8,5))\n",
    "# colors are in the order 5, 4, 3, 1, 2\n",
    "bar_colors = ['darkgreen', 'mediumseagreen', 'gold', 'crimson', 'orange']\n",
    "plot.bar(star_x, star_y, color=bar_colors, width=.6)\n",
    "plot.xlabel('Stars (Rating)')\n",
    "plot.ylabel('Number of Reviews')\n",
    "plot.title(f'Number of Reviews Per Rating of {businesses_to_analyse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    # Remove punctuation, symbols (#) and stopwords\n",
    "    doc = [tok.text for tok in doc if (tok.text.lower() not in stopwords and tok.pos_ != \"PUNCT\" and tok.pos_ != \"SYM\")]\n",
    "    # Make all tokens lowercase\n",
    "    doc = [tok.lower() for tok in doc]\n",
    "    doc = ' '.join(doc).replace(\"n't\",'not')\n",
    "    return nlp.make_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for index, restaurant in all_restaurants.iterrows():\n",
    "    print(f'Restaurant : {restaurant[\"name\"]} \\n')\n",
    "    for parsed_review in nlp.pipe(iter(all_reviews.query(' business_id == \"'+restaurant['business_id']+'\" ')['text']), batch_size=1000, n_threads=8):\n",
    "        docs.append(parsed_review)\n",
    "        print('\\n-------------')\n",
    "        print(parsed_review)\n",
    "        print('\\n-----')          \n",
    "        print(clean_doc(parsed_review))\n",
    "    if(index>0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "start = time.time()\n",
    "startbatch = time.time()\n",
    "print(f'Started at: {start:{20}}')\n",
    "total = len(all_reviews)\n",
    "#review['Parsed'] = all_reviews['text'].apply(nlp)\n",
    "for parsed_doc in nlp.pipe(iter(all_reviews['text']), batch_size=1000, n_threads=4):\n",
    "    docs.append(parsed_doc)\n",
    "    if len(docs) % 1000 == 0:\n",
    "        print(f'{len(docs)}/{total} processed in {time.time() - startbatch:>{5}} seconds')\n",
    "        startbatch = time.time()\n",
    "end   = time.time()\n",
    "print(f'End at:     {end:{20}}')\n",
    "print(f'Duration:   {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sample = all_reviews.head(10000)['text']\n",
    "review['Parsed'] = sample.apply(nlp)\n",
    "end   = time.time()\n",
    "print(f'Duration:   {end-start:{5}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"God is Great! I won a lottery.\"\n",
    "print(word_tokenize(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
