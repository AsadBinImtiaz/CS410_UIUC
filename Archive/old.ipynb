{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now we restrich Restaurants to this number to develop the code\n",
    "sample_restaurants_to_load = 10000\n",
    "\n",
    "# Only Arizona Businesses, Change if needed\n",
    "restaurant_file='processed_data/restaurants_az.csv'\n",
    "reviews_file   ='processed_data/restaurant_az_reviews.csv'\n",
    "\n",
    "# Number of topic\n",
    "NUM_TOPICS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is the large Spacy English Library\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords for topic mining\n",
    "stopwords = [line.rstrip('\\n') for line in open('config/stopwords.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The words that appear in names of the Restaurants\n",
    "# Restaurants name may appear multiple time in review, increasing its word frequenty\n",
    "# For topic mining per restaurant, it is not useful and should be removed\n",
    "# However words such as 'chicken' when come in restaurant name should be retained\n",
    "stopnames = [line.rstrip('\\n').lower() for line in open('config/names.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read Businesses\n",
    "all_restaurants = pd.read_csv(restaurant_file).drop(labels='Unnamed: 0', axis=1).head(sample_restaurants_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read all reviews\n",
    "all_reviews = pd.read_csv(reviews_file).drop(labels='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 246 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Retain reviews of selected Businesses\n",
    "all_reviews = all_reviews[all_reviews.business_id.isin(all_restaurants.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>QgV9RPyPUC3cAse1Wxqoow</td>\n",
       "      <td>P3cMpkppvBuVpPD8LBTbBQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Enjoyed Nee House immensely. No service issues...</td>\n",
       "      <td>2012-04-28 21:08:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>1ZTO6zFtVVxtXclHp4TvHQ</td>\n",
       "      <td>b1yLsCdv4ZL_d3INMCZzoA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm not sure how I rate this restaurant becaus...</td>\n",
       "      <td>2017-02-09 05:15:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>h17ep5S7O8_JMKovooWoVA</td>\n",
       "      <td>TaVuQWmXAhxy_LvIXBs9sg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>The food from this place reminds me of home. I...</td>\n",
       "      <td>2016-08-12 21:38:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>FVJaiFuf67Dzamax-zq1UQ</td>\n",
       "      <td>aCY0jMl8Jsvx_HQL4D3tmw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Found this place by just driving down the road...</td>\n",
       "      <td>2011-08-24 22:35:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>zqzOcreb9KBTaESR6qbTSg</td>\n",
       "      <td>TPZbqNXMA2xMXLLd1zL_0A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>We eat here on a regular basis.  It's like tha...</td>\n",
       "      <td>2013-04-11 02:26:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                          name     city state  \\\n",
       "0  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant  Phoenix    AZ   \n",
       "1  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant  Phoenix    AZ   \n",
       "2  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant  Phoenix    AZ   \n",
       "3  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant  Phoenix    AZ   \n",
       "4  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant  Phoenix    AZ   \n",
       "\n",
       "   business_stars  review_count            categories               review_id  \\\n",
       "0             3.5           269  Chinese, Restaurants  QgV9RPyPUC3cAse1Wxqoow   \n",
       "1             3.5           269  Chinese, Restaurants  1ZTO6zFtVVxtXclHp4TvHQ   \n",
       "2             3.5           269  Chinese, Restaurants  h17ep5S7O8_JMKovooWoVA   \n",
       "3             3.5           269  Chinese, Restaurants  FVJaiFuf67Dzamax-zq1UQ   \n",
       "4             3.5           269  Chinese, Restaurants  zqzOcreb9KBTaESR6qbTSg   \n",
       "\n",
       "                  user_id  review_stars  useful  \\\n",
       "0  P3cMpkppvBuVpPD8LBTbBQ           4.0       2   \n",
       "1  b1yLsCdv4ZL_d3INMCZzoA           3.0       0   \n",
       "2  TaVuQWmXAhxy_LvIXBs9sg           5.0       0   \n",
       "3  aCY0jMl8Jsvx_HQL4D3tmw           4.0       2   \n",
       "4  TPZbqNXMA2xMXLLd1zL_0A           4.0       2   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Enjoyed Nee House immensely. No service issues...  2012-04-28 21:08:22  \n",
       "1  I'm not sure how I rate this restaurant becaus...  2017-02-09 05:15:25  \n",
       "2  The food from this place reminds me of home. I...  2016-08-12 21:38:55  \n",
       "3  Found this place by just driving down the road...  2011-08-24 22:35:28  \n",
       "4  We eat here on a regular basis.  It's like tha...  2013-04-11 02:26:52  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Top 5 Reviews\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name_toks = []\n",
    "    \n",
    "    # Nlp doc from Name\n",
    "    name_doc = nlp(name)\n",
    "    for token in name_doc:\n",
    "        \n",
    "        # Retain Proper nouns in Name\n",
    "        if token.pos_ == 'PROPN' or token.like_num:\n",
    "        \n",
    "            # Lose stop words in Name\n",
    "            if token.text.lower() not in stopnames:\n",
    "            \n",
    "                # All Restaurant name tokens to be remoed from reviews of this reataurant\n",
    "                name_toks.append(token.text.lower())\n",
    "    return name_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc,name_toks):\n",
    "    \n",
    "    # Remove punctuation, symbols (#) and stopwords\n",
    "    #doc = [tok.text for tok in doc if (tok.text.lower() not in stopwords and tok.pos_ != \"PUNCT\" and tok.pos_ != \"SYM\")]\n",
    "    toks = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ \n",
    "            for tok in doc if (tok.text.lower().strip() not in stopwords and tok.text.lower() not in name_toks and tok.pos_ != \"SYM\" )]\n",
    "    \n",
    "    # Make all tokens lowercase\n",
    "    doc = [tok.lower() for tok in toks]\n",
    "    doc = ' '.join(doc).replace(\"n't\",'not').replace(' .','.').replace('  ',' ')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning reviews [    1/ 5216]\n",
      "Cleaning reviews [  101/ 5216]\n",
      "Cleaning reviews [  201/ 5216]\n",
      "Cleaning reviews [  301/ 5216]\n",
      "Cleaning reviews [  401/ 5216]\n",
      "Cleaning reviews [  501/ 5216]\n",
      "Cleaning reviews [  601/ 5216]\n",
      "Cleaning reviews [  701/ 5216]\n",
      "Cleaning reviews [  801/ 5216]\n",
      "Cleaning reviews [  901/ 5216]\n",
      "Cleaning reviews [ 1001/ 5216]\n",
      "Cleaning reviews [ 1101/ 5216]\n",
      "Cleaning reviews [ 1201/ 5216]\n",
      "Cleaning reviews [ 1301/ 5216]\n",
      "Cleaning reviews [ 1401/ 5216]\n",
      "Cleaning reviews [ 1501/ 5216]\n",
      "Cleaning reviews [ 1601/ 5216]\n",
      "Cleaning reviews [ 1701/ 5216]\n",
      "Cleaning reviews [ 1801/ 5216]\n",
      "Cleaning reviews [ 1901/ 5216]\n",
      "Cleaning reviews [ 2001/ 5216]\n",
      "Cleaning reviews [ 2101/ 5216]\n",
      "Cleaning reviews [ 2201/ 5216]\n",
      "Cleaning reviews [ 2301/ 5216]\n",
      "Cleaning reviews [ 2401/ 5216]\n",
      "Cleaning reviews [ 2501/ 5216]\n",
      "Cleaning reviews [ 2601/ 5216]\n",
      "Cleaning reviews [ 2701/ 5216]\n",
      "Cleaning reviews [ 2801/ 5216]\n",
      "Cleaning reviews [ 2901/ 5216]\n",
      "Cleaning reviews [ 3001/ 5216]\n",
      "Cleaning reviews [ 3101/ 5216]\n",
      "Cleaning reviews [ 3201/ 5216]\n",
      "Cleaning reviews [ 3301/ 5216]\n",
      "Cleaning reviews [ 3401/ 5216]\n",
      "Cleaning reviews [ 3501/ 5216]\n",
      "Cleaning reviews [ 3601/ 5216]\n",
      "Cleaning reviews [ 3701/ 5216]\n",
      "Cleaning reviews [ 3801/ 5216]\n",
      "Cleaning reviews [ 3901/ 5216]\n",
      "Cleaning reviews [ 4001/ 5216]\n",
      "Cleaning reviews [ 4101/ 5216]\n",
      "Cleaning reviews [ 4201/ 5216]\n",
      "Cleaning reviews [ 4301/ 5216]\n",
      "Cleaning reviews [ 4401/ 5216]\n",
      "Cleaning reviews [ 4501/ 5216]\n",
      "Cleaning reviews [ 4601/ 5216]\n",
      "Cleaning reviews [ 4701/ 5216]\n",
      "Cleaning reviews [ 4801/ 5216]\n",
      "Cleaning reviews [ 4901/ 5216]\n",
      "Cleaning reviews [ 5001/ 5216]\n",
      "Cleaning reviews [ 5101/ 5216]\n",
      "Cleaning reviews [ 5201/ 5216]\n",
      "Wall time: 7h 19min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = len(all_restaurants)\n",
    "cleansed_text = []\n",
    "for index, restaurant in all_restaurants.iterrows():\n",
    "    #print(f'Cleaning reviews for restaurant: \"{restaurant[\"name\"]:<{40}}\" [{index+1:>{5}}/{total:>{5}}]')\n",
    "    if index % 100 == 0:\n",
    "        print(f'Cleaning reviews [{index+1:>{5}}/{total:>{5}}]')\n",
    "    for parsed_review in nlp.pipe(iter(all_reviews.query(' business_id == \"'+restaurant['business_id']+'\" ')['text']), batch_size=1000, n_threads=8):\n",
    "        cleansed_text.append(clean_doc(parsed_review,clean_name(restaurant[\"name\"])))\n",
    "\n",
    "all_reviews['cleansed_text'] = cleansed_text\n",
    "all_reviews.to_csv('processed_data/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_reviews['cleansed_text'] = cleansed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_reviews[['text','cleansed_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_reviews.to_csv('processed_data/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant = all_restaurants.head(1).business_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = all_reviews[all_reviews.business_id == restaurant].cleansed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, max_df=0.9, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "data_vectorized = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Dirichlet Allocation Model\n",
    "lda = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=10, learning_method='online',verbose=True)\n",
    "data_lda = lda.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Negative Matrix Factorization Model\n",
    "nmf = NMF(n_components=NUM_TOPICS)\n",
    "data_nmf = nmf.fit_transform(data_vectorized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Semantic Indexing Model using Truncated SVD\n",
    "lsi = TruncatedSVD(n_components=NUM_TOPICS)\n",
    "data_lsi = lsi.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Topic Name\n",
    "def get_topic_name(tok):\n",
    "    topic_name_toks = []\n",
    "    doc = nlp(\" \".join(tok))\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    def remove_at(j):\n",
    "        topic_name_toks.append(tok[j].capitalize())\n",
    "        pos.remove(pos[j])\n",
    "        tok.remove(tok[j])\n",
    "    for x in range(5):\n",
    "        i = 0\n",
    "        if x % 2 == 0:\n",
    "            if  (\"ADJ\"   in pos) : i = pos.index(\"ADJ\")\n",
    "            elif(\"PROPN\" in pos) : i = pos.index(\"PROPN\")\n",
    "            elif(\"NOUN\"  in pos) : i = pos.index(\"NOUN\")\n",
    "            elif(\"ADV\"   in pos) : i = pos.index(\"ADV\")\n",
    "            elif(\"VERB\"  in pos) : i = pos.index(\"VERB\")\n",
    "            else :i=0\n",
    "        else:\n",
    "            if  (\"NOUN\"  in pos) : i = pos.index(\"NOUN\")\n",
    "            elif(\"PROPN\" in pos): i = pos.index(\"PROPN\")\n",
    "            elif(\"VERB\"  in pos) : i = pos.index(\"VERB\")\n",
    "            elif(\"ADV\"   in pos) : i = pos.index(\"ADV\")\n",
    "            else :i=0\n",
    "\n",
    "        remove_at(i)\n",
    "    \n",
    "    return \" \".join(topic_name_toks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for printing keywords for each topic\n",
    "def get_selected_topics(model, vectorizer, top_n=10):\n",
    "    topics = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        name = get_topic_name([vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        print(\"Topic Name: \"+name)\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        topics[idx]=name\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords for topics clustered by Latent Dirichlet Allocation\n",
    "print(\"LDA Model:\")\n",
    "selected_topics = get_selected_topics(lda, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be continued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
