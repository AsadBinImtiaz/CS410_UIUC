{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asad_\\Anaconda3\\lib\\site-packages\\thinc\\neural\\train.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from .optimizers import Adam, linear_decay\n",
      "C:\\Users\\asad_\\Anaconda3\\lib\\site-packages\\thinc\\check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "C:\\Users\\asad_\\Anaconda3\\lib\\site-packages\\thinc\\check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "C:\\Users\\asad_\\Anaconda3\\lib\\site-packages\\nltk\\decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Arizona Businesses, Change if needed\n",
    "restaurant_file='processed_data/cleaned_restaurants.csv'\n",
    "reviews_file   ='processed_data/cleaned_reviews.csv'\n",
    "\n",
    "# Number of topic\n",
    "NUM_TOPICS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is the large Spacy English Library\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "#  Stats\n",
    "## Wall time: 12.6 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read Businesses\n",
    "all_restaurants = pd.read_csv(restaurant_file).drop(labels='Unnamed: 0', axis=1)\n",
    "\n",
    "#  Stats\n",
    "## Wall time: 68 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read all reviews\n",
    "all_reviews = pd.read_csv(reviews_file).drop(labels='Unnamed: 0', axis=1)\n",
    "\n",
    "#  Stats\n",
    "## Wall time: 55.6 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_text</th>\n",
       "      <th>sentiment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>6W0MQHmasK0IsaoDo4bmkw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>My girlfriend and I went for dinner at Emerald...</td>\n",
       "      <td>girlfriend dinner thursday night workout arriv...</td>\n",
       "      <td>girlfriend dinner chinese. thursday night work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>BeeBfUxvzD4qNX4HxrgA5g</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>We've always been there on a Sunday so we were...</td>\n",
       "      <td>sunday saturday dim_sum luck surprise dish col...</td>\n",
       "      <td>sunday saturday dim_sum. busy. no luck surpris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>A1D2kUnZ0HTroFreAheNSg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>***No automatic doors, not baby friendly!*** I...</td>\n",
       "      <td>door post_partum dim_sum dish dinner time door...</td>\n",
       "      <td>no_automatic door not_baby friendly frequent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>2pf45Stf-pNew-xgTababQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible service,\\nI went there tonight with m...</td>\n",
       "      <td>tonight boyfriend pass couple time want try fr...</td>\n",
       "      <td>horrible_service tonight boyfriend because pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>RHhlmL07evgAdPaXQV8Omg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>One of the gauges of a good Chinese restaurant...</td>\n",
       "      <td>gauge patronize patron wife dim_sum brunch wee...</td>\n",
       "      <td>gauge good chinese_number chinese_people patro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                        name  business_stars  \\\n",
       "0  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "1  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "2  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "3  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "4  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "\n",
       "   review_count               review_id  review_stars  useful  \\\n",
       "0           128  6W0MQHmasK0IsaoDo4bmkw           3.0       3   \n",
       "1           128  BeeBfUxvzD4qNX4HxrgA5g           3.0       0   \n",
       "2           128  A1D2kUnZ0HTroFreAheNSg           3.0       0   \n",
       "3           128  2pf45Stf-pNew-xgTababQ           1.0       1   \n",
       "4           128  RHhlmL07evgAdPaXQV8Omg           4.0       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  My girlfriend and I went for dinner at Emerald...   \n",
       "1  We've always been there on a Sunday so we were...   \n",
       "2  ***No automatic doors, not baby friendly!*** I...   \n",
       "3  Horrible service,\\nI went there tonight with m...   \n",
       "4  One of the gauges of a good Chinese restaurant...   \n",
       "\n",
       "                                          topic_text  \\\n",
       "0  girlfriend dinner thursday night workout arriv...   \n",
       "1  sunday saturday dim_sum luck surprise dish col...   \n",
       "2  door post_partum dim_sum dish dinner time door...   \n",
       "3  tonight boyfriend pass couple time want try fr...   \n",
       "4  gauge patronize patron wife dim_sum brunch wee...   \n",
       "\n",
       "                                      sentiment_text  \n",
       "0  girlfriend dinner chinese. thursday night work...  \n",
       "1  sunday saturday dim_sum. busy. no luck surpris...  \n",
       "2  no_automatic door not_baby friendly frequent c...  \n",
       "3  horrible_service tonight boyfriend because pas...  \n",
       "4  gauge good chinese_number chinese_people patro...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Top 5 Reviews\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3527902"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant = all_restaurants.iloc[[0]].business_id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QXAEGFB4oINsVuTFxEYKFQ'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = all_reviews.query(' business_id == \"'+'44YFU284Z3KDEy25QyVoUw'+'\" ')['topic_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [u''+str(txt).replace('..','.').replace('  ',' ') for txt in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rate walk soup p.m. destroy need clear_sinuse trick tell supper time bowl soup home look cup soup price soup'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, max_df=0.9, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "data_vectorized = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    }
   ],
   "source": [
    "# Latent Dirichlet Allocation Model\n",
    "lda = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=10, learning_method='online',verbose=True)\n",
    "data_lda = lda.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Negative Matrix Factorization Model\n",
    "nmf = NMF(n_components=NUM_TOPICS)\n",
    "data_nmf = nmf.fit_transform(data_vectorized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Semantic Indexing Model using Truncated SVD\n",
    "lsi = TruncatedSVD(n_components=NUM_TOPICS)\n",
    "data_lsi = lsi.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Topic Name\n",
    "def get_topic_name(tok):\n",
    "    topic_name_toks = []\n",
    "    doc = nlp(\" \".join(tok))\n",
    "    pos = [token.pos_ for token in doc]\n",
    "    \n",
    "    def remove_at(j):\n",
    "        topic_name_toks.append(tok[j].capitalize())\n",
    "        pos.remove(pos[j])\n",
    "        tok.remove(tok[j])\n",
    "    for x in range(5):\n",
    "        i = 0\n",
    "        if x < 3:\n",
    "            if  (\"ADJ\"   in pos) : i = pos.index(\"ADJ\")\n",
    "            elif(\"PROPN\" in pos) : i = pos.index(\"PROPN\")\n",
    "            elif(\"NOUN\"  in pos) : i = pos.index(\"NOUN\")\n",
    "            elif(\"ADV\"   in pos) : i = pos.index(\"ADV\")\n",
    "            elif(\"VERB\"  in pos) : i = pos.index(\"VERB\")\n",
    "            else :i=0\n",
    "        elif x < 5:\n",
    "            if  (\"NOUN\"  in pos) : i = pos.index(\"NOUN\")\n",
    "            elif(\"PROPN\" in pos) : i = pos.index(\"PROPN\")\n",
    "            elif(\"VERB\"  in pos) : i = pos.index(\"VERB\")\n",
    "            elif(\"ADV\"   in pos) : i = pos.index(\"ADV\")\n",
    "            else :i=0\n",
    "        \n",
    "        remove_at(i)\n",
    "    \n",
    "    return \" \".join(topic_name_toks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_topic_name(tok, top_n=5):\n",
    "    return \" \".join(tok[:top_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for printing keywords for each topic\n",
    "def get_selected_topics(model, vectorizer, top_n=10):\n",
    "    topics = {}\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        name = get_simple_topic_name([vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        print(\"Topic Name: \"+name)\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        topics[idx]=name\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic 0:\n",
      "Topic Name: food customer owner love know\n",
      "[('food', 10.442763406634644), ('customer', 8.666571815435159), ('owner', 6.25502609259244), ('love', 6.12835815102017), ('know', 6.109367830380814), ('talk', 5.886121293324908), ('lady', 5.418721762210301), ('chinese', 5.111554349453622), ('rudeness', 4.852374432324161), ('business', 4.588639665342643)]\n",
      "Topic 1:\n",
      "Topic Name: food tell ask table service\n",
      "[('food', 56.91904027272681), ('tell', 44.91008688985316), ('ask', 41.407419247736385), ('table', 32.30837811390011), ('service', 26.565832260856297), ('wait', 25.910065817835868), ('waitress', 24.265851037637816), ('bring', 22.28567815979849), ('think', 21.838331956807423), ('eat', 20.79394128001787)]\n",
      "Topic 2:\n",
      "Topic Name: food service fry sauce chicken\n",
      "[('food', 115.99735478583672), ('service', 75.93692461887088), ('fry', 75.7520475111909), ('sauce', 72.04436087157103), ('chicken', 69.43585902189652), ('love', 64.75217519934466), ('dish', 61.96386119846564), ('rice', 61.85617754256503), ('time', 56.47663996274833), ('noodle', 46.66604463036541)]\n",
      "Topic 3:\n",
      "Topic Name: lunch menu seafood cod vegetable\n",
      "[('lunch', 18.801383770963508), ('menu', 9.089690358259636), ('seafood', 8.57311429817237), ('cod', 8.529140348356378), ('vegetable', 8.193577800727432), ('fish', 8.043864497523101), ('duck', 7.533043831859262), ('rock', 7.3819575056276125), ('crave', 6.4613484190524595), ('garlic', 6.393942046856287)]\n",
      "Topic 4:\n",
      "Topic Name: price friend location meal spot\n",
      "[('price', 5.7778102474077455), ('friend', 2.9544276740851583), ('location', 2.246752422259279), ('meal', 1.6936114113124616), ('spot', 1.6096065246404572), ('offer', 1.580834436970569), ('compare', 1.570397714195239), ('service', 1.195148170208014), ('family', 0.981263420347643), ('lot', 0.974007270147068)]\n"
     ]
    }
   ],
   "source": [
    "# Keywords for topics clustered by Latent Dirichlet Allocation\n",
    "print(\"LDA Model:\")\n",
    "selected_topics = get_selected_topics(lda, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'food customer owner love know', 1: 'food tell ask table service', 2: 'food service fry sauce chicken', 3: 'lunch menu seafood cod vegetable', 4: 'price friend location meal spot'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1> Clean the review -   machine readable (pre processing - remove stopwards, symbols, )\n",
    "2> Aspects > Topics     Topic modelling  ()\n",
    "3> Topics > catagories  catagorization   \n",
    "4> Semetimants > rating score/Aspects > LARA\n",
    "5> Optional > recommending\n",
    "\n",
    "\n",
    "Between 17 - 23 Asad  - Not Available\n",
    "                Karun - Not Available\n",
    "                Ron   - Not Available\n",
    "24 - 31         Asad  - step x \n",
    "                Dec 12 - Dec 16 (4 days)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(name,path):\n",
    "    ret = None\n",
    "    try:\n",
    "        with open(path+\"/\"+name, 'r') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    except:\n",
    "        with open(bucket+path+\"/\"+name) as f:\n",
    "            return f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-86aef3745793>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config/stopwords.txt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-18b92cd964ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-86aef3745793>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bucket' is not defined"
     ]
    }
   ],
   "source": [
    "x = read_file('stopwords.txt','config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
