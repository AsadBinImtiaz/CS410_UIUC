{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libs\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# Mongo DB\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from MongoDB\n",
    "DBClient = MongoClient()\n",
    "yelp_data = DBClient.yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select business having atleast 50 reviews\n",
    "min_review_count = 50\n",
    "\n",
    "# businesses to Analyse\n",
    "businesses_to_analyse = 'Restaurants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all restaurant businesses\n",
    "Restaurant_business = pd.DataFrame(yelp_data.business.find({\"categories\":{\"$regex\" :\".*\"+businesses_to_analyse+\".*\"}, \"review_count\":{\"$gte\":min_review_count} },  {'business_id':1, 'name':1, 'city':1, 'state':1, 'stars':1, 'review_count':1, 'categories':1, '_id': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all reviews\n",
    "All_reviews = pd.DataFrame(yelp_data.review.find({},{'review_id':1, 'user_id':1, 'business_id':1, 'stars':1, 'useful':1, 'text':1, 'date':1, '_id': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all restaurant reviews\n",
    "#Restaurant_reviews = All_reviews[All_reviews.business_id.isin(Restaurant_business.business_id.values)]\n",
    "Restaurant_reviews = pd.merge(Restaurant_business,All_reviews, on='business_id').rename(columns={'stars_x':'business_stars', 'stars_y':'review_stars'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 5 Restaurant\n",
    "Restaurant_business.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 5 Reviews\n",
    "Restaurant_reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write selected Restaurants to file\n",
    "Restaurant_reviews.to_csv('processed_data/restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write selected Restaurant-reviews to file\n",
    "Restaurant_business.to_csv('processed_data/restaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many reviews we have of each star\n",
    "star_x = Restaurant_reviews.review_stars.value_counts().index\n",
    "star_y = Restaurant_reviews.review_stars.value_counts().values\n",
    "\n",
    "plot.figure(figsize=(8,5))\n",
    "# colors are in the order 5, 4, 3, 1, 2\n",
    "bar_colors = ['darkgreen', 'mediumseagreen', 'gold', 'crimson', 'orange']\n",
    "plot.bar(star_x, star_y, color=bar_colors, width=.6)\n",
    "plot.xlabel('Stars (Rating)')\n",
    "plot.ylabel('Number of Reviews')\n",
    "plot.title(f'Number of Reviews Per Rating of {businesses_to_analyse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_business.groupby('state').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_per_state = Restaurant_business.groupby('state').count()[['business_id']].rename(columns={'state': 'State', 'business_id': 'Restaurants'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_per_state.sort_values(by='Restaurants').plot.bar(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_AZ = pd.DataFrame(yelp_data.business.find({\"categories\":{\"$regex\" :\".*\"+businesses_to_analyse+\".*\"}, \"review_count\":{\"$gte\":min_review_count}, \"state\":\"AZ\" },  {'business_id':1, 'name':1, 'city':1, 'state':1, 'stars':1, 'review_count':1, 'categories':1, '_id': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_AZ_reviews = pd.merge(Restaurant_AZ,All_reviews, on='business_id').rename(columns={'stars_x':'business_stars', 'stars_y':'review_stars'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_AZ_reviews.to_csv('processed_data/restaurant_az_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_AZ.to_csv('processed_data/restaurants_az.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_AZ_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many reviews we have of each star\n",
    "star_x = Restaurant_AZ_reviews.review_stars.value_counts().index\n",
    "star_y = Restaurant_AZ_reviews.review_stars.value_counts().values\n",
    "\n",
    "plot.figure(figsize=(8,5))\n",
    "# colors are in the order 5, 4, 3, 1, 2\n",
    "bar_colors = ['darkgreen', 'mediumseagreen', 'gold', 'crimson', 'orange']\n",
    "plot.bar(star_x, star_y, color=bar_colors, width=.6)\n",
    "plot.xlabel('Stars (Rating)')\n",
    "plot.ylabel('Number of Reviews')\n",
    "plot.title(f'Number of Reviews Per Rating of {businesses_to_analyse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now we restrich Restaurants to this number to develop the code\n",
    "sample_restaurants_to_load = 10\n",
    "\n",
    "# Only Arizona Businesses, Change if needed\n",
    "restaurant_file='processed_data/restaurants_az.csv'\n",
    "reviews_file   ='processed_data/restaurant_az_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SPACY\n",
    "# This is the large Spacy English Library\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp2 = spacy.load('en_core_web_lg', disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords for topic mining\n",
    "stopwords = [line.rstrip('\\n') for line in open('config/stopwords.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The words that appear in names of the Restaurants\n",
    "# Restaurants name may appear multiple time in review, increasing its word frequenty\n",
    "# For topic mining per restaurant, it is not useful and should be removed\n",
    "# However words such as 'chicken' when come in restaurant name should be retained\n",
    "stopnames = [line.rstrip('\\n').lower() for line in open('config/names.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read Businesses\n",
    "all_restaurants = pd.read_csv(restaurant_file).drop(labels='Unnamed: 0', axis=1).head(sample_restaurants_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read all reviews\n",
    "all_reviews = pd.read_csv(reviews_file).drop(labels='Unnamed: 0', axis=1).drop(labels='city', axis=1).drop(labels='state', axis=1).drop(labels='categories', axis=1).drop(labels='user_id', axis=1).drop(labels='date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Retain reviews of selected Businesses\n",
    "all_reviews = all_reviews[all_reviews.business_id.isin(all_restaurants.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.01 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>QgV9RPyPUC3cAse1Wxqoow</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Enjoyed Nee House immensely. No service issues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>1ZTO6zFtVVxtXclHp4TvHQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm not sure how I rate this restaurant becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>h17ep5S7O8_JMKovooWoVA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>The food from this place reminds me of home. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>FVJaiFuf67Dzamax-zq1UQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Found this place by just driving down the road...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44YFU284Z3KDEy25QyVoUw</td>\n",
       "      <td>Nee House Chinese Restaurant</td>\n",
       "      <td>3.5</td>\n",
       "      <td>269</td>\n",
       "      <td>zqzOcreb9KBTaESR6qbTSg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>We eat here on a regular basis.  It's like tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                          name  business_stars  \\\n",
       "0  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant             3.5   \n",
       "1  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant             3.5   \n",
       "2  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant             3.5   \n",
       "3  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant             3.5   \n",
       "4  44YFU284Z3KDEy25QyVoUw  Nee House Chinese Restaurant             3.5   \n",
       "\n",
       "   review_count               review_id  review_stars  useful  \\\n",
       "0           269  QgV9RPyPUC3cAse1Wxqoow           4.0       2   \n",
       "1           269  1ZTO6zFtVVxtXclHp4TvHQ           3.0       0   \n",
       "2           269  h17ep5S7O8_JMKovooWoVA           5.0       0   \n",
       "3           269  FVJaiFuf67Dzamax-zq1UQ           4.0       2   \n",
       "4           269  zqzOcreb9KBTaESR6qbTSg           4.0       2   \n",
       "\n",
       "                                                text  \n",
       "0  Enjoyed Nee House immensely. No service issues...  \n",
       "1  I'm not sure how I rate this restaurant becaus...  \n",
       "2  The food from this place reminds me of home. I...  \n",
       "3  Found this place by just driving down the road...  \n",
       "4  We eat here on a regular basis.  It's like tha...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Top 5 Reviews\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_docs(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String List cleaning, removes spaces, new lines\n",
    "def clean_string(data):\n",
    "    data = [re.sub('\\s+', ' '  , sent) for sent in data]\n",
    "    data = [re.sub(\"n't\", 'not', sent) for sent in data]\n",
    "    data = [sent.lower()               for sent in data]\n",
    "    data = list(tokenize_docs(data))\n",
    "    data = [[tok for tok in sent if tok not in stopwords ] for sent in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name_toks = []\n",
    "    \n",
    "    # Nlp doc from Name\n",
    "    name_doc = nlp(name)\n",
    "    for token in name_doc:\n",
    "        \n",
    "        # Retain Proper nouns in Name\n",
    "        if token.pos_ == 'PROPN' or token.like_num:\n",
    "        \n",
    "            # Lose stop words in Name\n",
    "            if token.text.lower() not in stopnames:\n",
    "            \n",
    "                # All Restaurant name tokens to be remoed from reviews of this reataurant\n",
    "                name_toks.append(token.text.lower())\n",
    "    \n",
    "    #for noun_phrase in list(name_doc.noun_chunks):\n",
    "        #if(len(str(noun_phrase).split())<2):\n",
    "            #noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_)\n",
    "    \n",
    "    \n",
    "    for chunk in name_doc.ents:\n",
    "        name_toks.append(chunk.text.lower())\n",
    "    \n",
    "    return name_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc,name_toks,allowed_postags=['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \n",
    "    # Remove punctuation, symbols (#) and stopwords\n",
    "    allowed_postags=['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "    \n",
    "    toks = [tok.lemma_ for tok in doc ]\n",
    "    doc = nlp2(\" \".join(toks))\n",
    "    \n",
    "    [noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_) for noun_phrase in doc.noun_chunks if len(str(noun_phrase).split())>1 and len(str(noun_phrase).split())<4]\n",
    "    \n",
    "    #doc = [tok.text for tok in doc if (tok.text.lower() not in stopwords and tok.pos_ != \"PUNCT\" and tok.pos_ != \"SYM\")]\n",
    "    toks = [tok.text.lower().strip().replace('_',' ') for tok in doc \n",
    "                if (tok.text.lower().strip().replace('_',' ') not in stopwords \n",
    "                    and tok.text.lower().replace('_',' ') not in name_toks \n",
    "                    and tok.pos_ in allowed_postags\n",
    "                   )]\n",
    "    return \" \".join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning reviews [    1/   10]\n",
      "('enjoy immensely service issue fantastic chinese food food spicy green beans '\n",
      " 'perfect chow fun chicken perfect great expectation set bad service review '\n",
      " 'disappointed')\n",
      "('not sure rate walk soup pm destroy need clear sinus hot sour soap always '\n",
      " 'trick tell couldnot cup supper time okay order bowl soup home okay thing '\n",
      " 'look cup soup fresh good sure price high bowl soup wasnot great much broth')\n",
      "('food remind home taiwanese little island china food taste hong kong american '\n",
      " 'favorite local classic mongolian beef citrus orange chicken personally mix '\n",
      " 'feeling more cultural grab lobster garlic chinese broccoli oyster sauce '\n",
      " 'warning expect dish bitter value taste chinese cuisine today grab mongolian '\n",
      " 'beef fried rice egg roll girlfriend home chicken fry rice egg roll dude egg '\n",
      " 'roll bite entree seriously portion huge expect leftover merry moment later '\n",
      " 'day finish food caveat donot expect service kind truly authentic chinese '\n",
      " 'expect customer service standard tgif chinese point food sit food pay bill '\n",
      " 'donot chit chat')\n",
      "('find drive road lunch car decide stop wednesday lunch time greet fairly fast '\n",
      " 'wear chef outfit sit right lunch menu include soup rice egg roll garlic '\n",
      " 'chicken delicious clean nose right spicy derive fast colleague enjoy lunch '\n",
      " 'fresh fish lobster crab price post wall no surprise waitress sensitive fact '\n",
      " 'work gent lunch break lay senior citizen dining time always water regular '\n",
      " 'rotation lunch excite try')\n",
      "('eat regular basis little hole wall tasty food reasonable price vouch menu '\n",
      " 'always chicken spicy garlic sauce lunch special spring roll fried white rice '\n",
      " 'delicious love white meat chicken lot veggie hole wall donot mean bad way '\n",
      " 'good food lot time always look decently clean decently word love dish '\n",
      " 'suggest')\n",
      "('good chinese food ve long time service good add charm food more always salt '\n",
      " 'pepper pork chop perfectly season batter spice lobster xo sauce plentiful '\n",
      " 'lot yummy flavor spicy depend jalapenos salt pepper squid perfectly battered '\n",
      " 'piece squid no leg deep fried absolute perfection beef chow fun yummy flat '\n",
      " 'rice noodle tender pc beef sprout onion green onion chinese broccoli menu '\n",
      " 'ask stock sauteed garlic dry fish awesome sauce price reasonable expensive '\n",
      " 'compare always eat visit az')\n",
      "('star rating service wait promptly food timely manner waitress extremely rude '\n",
      " 'visit family pay meal tell people wait table wasnot pleasant minute pay '\n",
      " 'never ask leave table happy meal donot think kind treatment unacceptable')\n",
      "('service shotty pretty authentic chinese food worth shoot mind small staff '\n",
      " 'talk more customer')\n",
      "('previous review real detail love food update grumpy girl more friendly '\n",
      " 'yesterday grab smile small conversation exude sullen disposition way happy '\n",
      " 'happy usual item mongolian beef tasty stil partial ginger beef')\n",
      "('perfect neighborhood family run chinese offer reliable delicious chinese '\n",
      " 'food year almost always open basic orange chicken lunch menu way peking duck '\n",
      " 'live crabs lobster fish dish deliciously prepare online menu mislead large '\n",
      " 'selection wonderful chinese food today lunch orange chicken lunch special '\n",
      " 'food nice hot sweet tangy sauce chicken cook tender juicy dish egg roll soup '\n",
      " 'choice fried rice white rice kids beef chow fun garlic snow pea leaf salt '\n",
      " 'pepper pork chops walnut shrimp food fantastic pork chop mouth water hot '\n",
      " 'bite jalapeno slice right salt chow fun tasty flat rice noodle dish beef '\n",
      " 'shrimp chicken noodle cook season deliciousness snow pea leaf warm rich '\n",
      " 'green color nice salty garlic flavor crunchy texture walnut shrimp '\n",
      " 'overcooked eat candy bathroom malodorous service typical great chinese year')\n",
      "('read decent review close home decide try young lady counter impatient '\n",
      " 'interpersonal skill food good chinese good')\n",
      "('wow impressed taste food amazing dish range simple orange chicken turnip '\n",
      " 'deef hot pot fan style chinese food hit craving')\n",
      "('service grab seat slow minute donot care soon sit waitress leave minute '\n",
      " 'later food warm cold luck find piece hair tell fault donot want rude people '\n",
      " 'dirty kitchen')\n",
      "('fresh authentic chinese food especially love seafood dish best hot sour soup '\n",
      " 've perfect ail')\n",
      "'nostalgia play want experience chinese food grow nee house spot'\n",
      "('way rate close china town style hard find dessert service isnot custom real '\n",
      " 'gem')\n",
      "('office bay area collegue mad search good great chinese difficult find high '\n",
      " 'quality fresh ingredient offer excellent flavor certainly par bay area '\n",
      " 'chinatown yes staff touch surly true indication authentic thing course surly '\n",
      " 'chinese excellent food wait try treat tell friend need open')\n",
      "('west lake beef soup pretty good beef chow fun daughter rate pretty low beef '\n",
      " 'cut big irregular pretty bland lack season comparison daughter jade palace '\n",
      " 'americanize bastion north scottsdale chinese beef chow fun well rock codfish '\n",
      " 'black bean sauce pretty tasty sauce fish wasnot bad cod sure small portion '\n",
      " 'rice accompany price bad return')\n",
      "('mom love good food big portion price favorite bbq duck peking duck item try '\n",
      " 'good service star guy')\n",
      "('family eat canot remember almost always takeout pan fried noodle fantastic '\n",
      " 'especially noodle extra crispy pineaple chicken yummy black bean shrimp '\n",
      " 'delicious fry rice amazing especially fried rice pork shrimp good dad travel '\n",
      " 'china lot work authentic get area')\n",
      "('disappointed lack flavor beef chow fun cook soggy no flavor interested '\n",
      " 'simple dish wrong')\n",
      "('wait staff nasty food rude unfriendly service act annoyed dine meat chicken '\n",
      " 'spongy bland worked food service guessing use process meat product use '\n",
      " 'extremely cheap doesnot refrigerate leave plate food inedible')\n",
      "('love great price great food ve never eat sure atmosphere ve never bad '\n",
      " 'experience')\n",
      "('great service good mongolian beef lunch special soup egg roll good hot tea '\n",
      " 'left later')\n",
      "('look good chinese great reviews yelp husband decide stop dinner tonight glad '\n",
      " 'little gem small strip mall food more compensate ambiance try general tso '\n",
      " 'chicken mongolian beef garlic szechuan green beans spicy chicken tender nice '\n",
      " 'light batter beef more tender possible love enjoy sauce nice combination '\n",
      " 'spice sweet garlic pm table fill pretty quickly amazing job takeout notice '\n",
      " 'steady stream people head door bag food definitely takeout food future')\n",
      "('asian raise cantonese hong kong style cuisine style szechuan spicy style '\n",
      " 'thie good way chinese seafood specialty crispy noodle chow mein stuff good '\n",
      " 'east coast chicago lucky az generic fry rice egg rolls orange chicken buffet '\n",
      " 'panda express rest enjoy truly traditional delicious fare')\n",
      "('waste time eat night waste more time detailed review donot know wrong run '\n",
      " 'let suffice vial not edible item eat leave home hungry bad chinese food '\n",
      " 'stick super dragon drive')\n",
      "('egg cellent chicken fried rice boyfriend food smell bad fun rest night sad '\n",
      " 'donot jerk boyfriend allergic asian highly recommmend')\n",
      "('dinner night delicious enjoy sizzling rice seafood soup savory garlic string '\n",
      " 'bean tender cashew chicken beef black bean sauce mix vegetable look forward '\n",
      " 'trekking mesa soon downside wait staff inattentive careless serve guest')\n",
      "('offer excellent chinese food offer live crab lobster good class chinese food '\n",
      " 'spicy style wrong waiter service horrible need improve')\n",
      "('often write scathing review constructive criticism want walk moment walk '\n",
      " 'parent suggest good hole wall type amazing food think stick thing south fast '\n",
      " 'veggie egg roll total frozen middle wife mother pull dead fly bok choy cod '\n",
      " 'dish dad agree sauce garlic eggplant gross steam white rice bad mess steam '\n",
      " 'white rice shrimp fried rice never arrive maybe never stay away')\n",
      "('family love varied taste enjoy explore entire menu favorite eggplant shrimp '\n",
      " 'schezuan sauce staff friendly efficient much current trend smother attention '\n",
      " 'highly recommend')\n",
      "('excite try friend recommend friend lunch yesterday eggplant tou fu fire mix '\n",
      " 'vegs brown sauce definitely chinese style couple bite leave price pretty '\n",
      " 'expensive meal run lunch')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('good chinese food northern phoenix maybe entire metro area wife sample '\n",
      " 'chinese cultural district opinion better good general tso chicken region '\n",
      " 'little twist think ginger certain set apart form competition general tso '\n",
      " 'rivals competition west coast east coast noodle fantastic fresh ingredient '\n",
      " 'vegetable eggplant shrimp outstanding reason didnot nee house star admit '\n",
      " 'picky dish look entire phoenix metro area admittedly focus sichuan style '\n",
      " 'dish dish look sichuan spicy cold chicken noodle fall love live bay area '\n",
      " 'impossible find phoenix metro area want authentic delicious chinese food '\n",
      " 'sure try')\n",
      "('recent lunch change opinion crab dried scallop fried rice good best fry rice '\n",
      " 've eat live hong kong rice kernel perfectly al dente greasy seasoned right '\n",
      " 'restraint breath wok shine deliciously fry rice noodle real skill chef '\n",
      " 'require good control heat timing lobster house special sauce lobster pluck '\n",
      " 'live tank weigh lbs lb total approx sauce addictively spicy slice jalapenos '\n",
      " 'ample ground black pepper crunch green onion little sugar sauce perfect '\n",
      " 'young favorite vegetable usually available lot traffic chinese customer '\n",
      " 'appreciate require plucking remove tender tendril tend cost more cost plate '\n",
      " 'high resist flavor texture small tender dark green leave serve ask cook '\n",
      " 'garlic cook perfect level bad overcooked vegetable bit oily fry rice more '\n",
      " 'reason')\n",
      "('regular roberta crab rangoon lemon fish pretty much regular vietnamese egg '\n",
      " 'roll shrimp special red sauce favorite eat large number chinese year right '\n",
      " 'worth way visit')\n",
      "'cockroach advise owner wasnot surprise apologetic needless leave ordering'\n",
      "'love try food live neighborhood live mile away pick food time month star'\n",
      "'gross stay away food bad service mediocre small bite spit right never'\n",
      "('good chinese secret ahead live fish day wife love black bean fish die walnut '\n",
      " 'shrimp lot native camp know good food kettle')\n",
      "'better generic fry rice day old hot sour soup lack depth waste money'\n",
      "('dine second time sunday food excellent second time experience poor service '\n",
      " 'thought aberration visit wait staff exceedingly rude point exasperation not '\n",
      " 'attentive act endure ask hot tea repeatedly entree arrive time gap ask '\n",
      " 'repeatedly accompany rice insult end experience present bill ask wait '\n",
      " 'staffer vacate table wait table table vacant definitely never return venue')\n",
      "('find authentic chinese food scottsdale difficult solution problem menu yelp '\n",
      " 'extensive saw menu amazed choice eat week cover want')\n",
      "('search decent chinese ne phoenix think ve find chicken friend rice sweet '\n",
      " 'sour chicken disappoint love sweet sour chicken prepare cooked sauce instead '\n",
      " 'batter fry chicken sauce return try dish')\n",
      "('ve year dirrerent year wonot year year times week owner tell tomorrow lunch '\n",
      " 'day week look diner menu always dinner menu lunch time early friend realize '\n",
      " 'eat menu fan group people dish possible start soup seafood soup favorite '\n",
      " 'favorite main dish include rock cod black bean sauce mapo tofu green '\n",
      " 'vegetable canot remember know mean picture menu singapore noodle dinner ask '\n",
      " 'cook fish fish lobster reservation week advance shaoxing wine 紹興酒 donot '\n",
      " 'bottle request orddered bottle warm shaoxing shu slice ginger food serve '\n",
      " 'special menu chinese new year learn read lot dish chinese service quuality '\n",
      " 'food always consistent authentic chinese food north phoenix chinese food '\n",
      " 'china')\n",
      "('donot damn good bad food poor customer service deal breaker never donot care '\n",
      " 'spending money help')\n",
      "('echo sentiment good food bad service takeout pay woman counter disappear sit '\n",
      " 'minute woman scurry set bag food kid foot stop quickly turn scurry kitchen '\n",
      " 'shout box walk pick bag second break course soup donot desire eat base '\n",
      " 'experience review ton food pretty good')\n",
      "('stop late lunch walk pm sight fellow customer staff moment nice lady '\n",
      " 'instruct seat appear ready sit late lunch early family dinner table linen '\n",
      " 'remainder uncover lunch clean simple awe inspire wasnot decor food food '\n",
      " 'outstanding ve eat chinese country especially ny chicago unfortunately '\n",
      " 'chinese food phoenix disappoint far today end negative experience ve far '\n",
      " 'order spicy shrimp eggplant fry rice egg roll hot sour soup lunch menu food '\n",
      " 'arrive hot egg roll crispy tasty hot sour soup good havenot lunch plate '\n",
      " 'arrive feast eye food hot wok seriously hot fried rice good ve short grained '\n",
      " 'rice greasy entente eggplant die sweet tender flavorful dark sauce surround '\n",
      " 'bountiful wonderful shrimp savor bite happy food hot force eat slowly savor '\n",
      " 'bite actually home dream meal want return day litterally eat grain rice '\n",
      " 'plate want pick lick good definitely canot wait lunch dinner try more great '\n",
      " 'food way read grumpy family find unpleasant fact nice')\n",
      "'great chinese food find much takeout sit dining fine'\n",
      "('follow yelp review daughter try week service attentive food good portions '\n",
      " 'large fried rice greasy find chinese restaurant area probably week')\n",
      "'horrible service nasty staff owner mean smile flavorless expensive never'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: '<timed exec>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-cad6000a29fb>\u001b[0m in \u001b[0;36mclean_doc\u001b[1;34m(doc, name_toks, allowed_postags)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ment_type_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnoun_phrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#doc = [tok.text for tok in doc if (tok.text.lower() not in stopwords and tok.pos_ != \"PUNCT\" and tok.pos_ != \"SYM\")]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-cad6000a29fb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoun_phrase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ment_type_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnoun_phrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#doc = [tok.text for tok in doc if (tok.text.lower() not in stopwords and tok.pos_ != \"PUNCT\" and tok.pos_ != \"SYM\")]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mspan.pyx\u001b[0m in \u001b[0;36mspacy.tokens.span.Span.merge\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\errors.py\u001b[0m in \u001b[0;36mdeprecation_warning\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m     \u001b[0m_warn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"deprecation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\errors.py\u001b[0m in \u001b[0;36m_warn\u001b[1;34m(message, warn_type)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwarn_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSPACY_WARNING_TYPES\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mcategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWARNINGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwarn_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m         \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSPACY_WARNING_FILTER\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m   1511\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1512\u001b[0m     \u001b[1;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1513\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1488\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m         \u001b[0mframeinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1491\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m             \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1465\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    766\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Invalidate cache if needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    691\u001b[0m                  importlib.machinery.EXTENSION_SUFFIXES):\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = len(all_restaurants)\n",
    "cleansed_text = []\n",
    "for index, restaurant in all_restaurants.iterrows():\n",
    "    #print(f'Cleaning reviews for restaurant: \"{restaurant[\"name\"]:<{40}}\" [{index+1:>{5}}/{total:>{5}}]')\n",
    "    if index % 100 == 0:\n",
    "        print(f'Cleaning reviews [{index+1:>{5}}/{total:>{5}}]')\n",
    "    \n",
    "    # Convert to list\n",
    "    data = all_reviews.query(' business_id == \"'+restaurant['business_id']+'\" ')['text']\n",
    "    \n",
    "    # Remove new lines, spaces, etc. Remove stopwords\n",
    "    data = clean_string(data)\n",
    "    \n",
    "    # Build the bigram and trigram models\n",
    "    bigram  = gensim.models.Phrases(data, min_count=4, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data],min_count=3, threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod  = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    bigrams  = [bigram_mod[doc] for doc in data]\n",
    "    trigrams = [trigram_mod[bigram_mod[doc]] for doc in data]\n",
    "    \n",
    "    data = [\" \".join(trigram) for trigram in trigrams]\n",
    "    #data = [\" \".join(toks) for toks in data] \n",
    "    \n",
    "    # iterate list, clean sentences\n",
    "    for parsed_review in nlp.pipe(iter(data), batch_size=1000, n_threads=8):\n",
    "        #[noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_) for noun_phrase in parsed_review.noun_chunks if len(str(noun_phrase).split())>1 and len(str(noun_phrase).split())<4]\n",
    "        cleansed_text.append(clean_doc(parsed_review,clean_name(restaurant[\"name\"])))\n",
    "        pprint(cleansed_text[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-add2a27fe828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleansed_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleansed_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mall_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'processed_data/cleaned_reviews.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mall_restaurants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'processed_data/cleaned_restaurants.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3471\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3472\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3548\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3549\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3550\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3733\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3734\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "all_reviews['cleansed_text'] = cleansed_text\n",
    "all_reviews.to_csv('processed_data/cleaned_reviews.csv')\n",
    "all_restaurants.to_csv('processed_data/cleaned_restaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
