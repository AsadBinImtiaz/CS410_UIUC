{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = os.path.join('pickles/sentiment_analysis')\n",
    "cleaned_reviews_file = os.path.join(pickle_dir, 'cleaned_reviews_df.pkl')\n",
    "df_classes_file = os.path.join(pickle_dir, 'df_classes.pkl')\n",
    "vocab_file = os.path.join(pickle_dir, 'cleaned_reviews_vocab.pkl')\n",
    "transformed_sentiment_file = os.path.join(pickle_dir, 'cleaned_reviews_x_sentiment.pkl')\n",
    "classifier_file = os.path.join(pickle_dir, 'mnb_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 == 1:\n",
    "    import sys\n",
    "    !conda install --yes --prefix {sys.prefix} s3fs seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_s3_bucket(bucket, data_key):\n",
    "    data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "    chunksize = 1000000\n",
    "    chunk_list = []\n",
    "    df_chunk = pd.read_csv(data_location, chunksize=chunksize)\n",
    "    for chunk in df_chunk:\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    df = pd.concat(chunk_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 11.1 s, total: 1min 2s\n",
      "Wall time: 9min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1 == 1:\n",
    "    \n",
    "    bucket = 'cs410-yelp'\n",
    "    data_key = 'processed_data/cleaned_reviews.csv'\n",
    "\n",
    "    df = read_s3_bucket(bucket, data_key)\n",
    "    df = df.drop(labels='Unnamed: 0', axis=1)\n",
    "    df['review_stars']   = df['review_stars'].astype(int)\n",
    "    df['sentiment_text'] = df['sentiment_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_text</th>\n",
       "      <th>sentiment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>6W0MQHmasK0IsaoDo4bmkw</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>My girlfriend and I went for dinner at Emerald...</td>\n",
       "      <td>girlfriend dinner thursday night workout arriv...</td>\n",
       "      <td>girlfriend dinner chinese. thursday night work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>BeeBfUxvzD4qNX4HxrgA5g</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We've always been there on a Sunday so we were...</td>\n",
       "      <td>sunday saturday dim_sum luck surprise dish col...</td>\n",
       "      <td>sunday saturday dim_sum. busy. no luck surpris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>A1D2kUnZ0HTroFreAheNSg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>***No automatic doors, not baby friendly!*** I...</td>\n",
       "      <td>door post_partum dim_sum dish dinner time door...</td>\n",
       "      <td>no_automatic door not_baby friendly frequent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>2pf45Stf-pNew-xgTababQ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible service,\\nI went there tonight with m...</td>\n",
       "      <td>tonight boyfriend pass couple time want try fr...</td>\n",
       "      <td>horrible_service tonight boyfriend because pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>2.5</td>\n",
       "      <td>128</td>\n",
       "      <td>RHhlmL07evgAdPaXQV8Omg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>One of the gauges of a good Chinese restaurant...</td>\n",
       "      <td>gauge patronize patron wife dim_sum brunch wee...</td>\n",
       "      <td>gauge good chinese_number chinese_people patro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                        name  business_stars  \\\n",
       "0  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "1  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "2  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "3  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "4  QXAEGFB4oINsVuTFxEYKFQ  Emerald Chinese Restaurant             2.5   \n",
       "\n",
       "   review_count               review_id  review_stars  useful  \\\n",
       "0           128  6W0MQHmasK0IsaoDo4bmkw             3       3   \n",
       "1           128  BeeBfUxvzD4qNX4HxrgA5g             3       0   \n",
       "2           128  A1D2kUnZ0HTroFreAheNSg             3       0   \n",
       "3           128  2pf45Stf-pNew-xgTababQ             1       1   \n",
       "4           128  RHhlmL07evgAdPaXQV8Omg             4       2   \n",
       "\n",
       "                                                text  \\\n",
       "0  My girlfriend and I went for dinner at Emerald...   \n",
       "1  We've always been there on a Sunday so we were...   \n",
       "2  ***No automatic doors, not baby friendly!*** I...   \n",
       "3  Horrible service,\\nI went there tonight with m...   \n",
       "4  One of the gauges of a good Chinese restaurant...   \n",
       "\n",
       "                                          topic_text  \\\n",
       "0  girlfriend dinner thursday night workout arriv...   \n",
       "1  sunday saturday dim_sum luck surprise dish col...   \n",
       "2  door post_partum dim_sum dish dinner time door...   \n",
       "3  tonight boyfriend pass couple time want try fr...   \n",
       "4  gauge patronize patron wife dim_sum brunch wee...   \n",
       "\n",
       "                                      sentiment_text  \n",
       "0  girlfriend dinner chinese. thursday night work...  \n",
       "1  sunday saturday dim_sum. busy. no luck surpris...  \n",
       "2  no_automatic door not_baby friendly frequent c...  \n",
       "3  horrible_service tonight boyfriend because pas...  \n",
       "4  gauge good chinese_number chinese_people patro...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3527902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.374313</td>\n",
       "      <td>507.893546</td>\n",
       "      <td>1.431601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.529216</td>\n",
       "      <td>569.256905</td>\n",
       "      <td>1.338946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.633498</td>\n",
       "      <td>615.480560</td>\n",
       "      <td>1.189830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.790773</td>\n",
       "      <td>633.882706</td>\n",
       "      <td>1.206635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.983838</td>\n",
       "      <td>647.555980</td>\n",
       "      <td>0.896749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_stars  review_count    useful\n",
       "review_stars                                        \n",
       "1                   3.374313    507.893546  1.431601\n",
       "2                   3.529216    569.256905  1.338946\n",
       "3                   3.633498    615.480560  1.189830\n",
       "4                   3.790773    633.882706  1.206635\n",
       "5                   3.983838    647.555980  0.896749"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stval = df.groupby('review_stars').mean()\n",
    "stval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [line.rstrip('\\n') for line in open('config/stopwords.txt', 'r', encoding='utf-8')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = frozenset(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(473700, 10)\n",
      "3     horrible_service tonight boyfriend because pas...\n",
      "14    big chinese_mississauga solid good_food. recen...\n",
      "25    time year definitely_change quality food gone_...\n",
      "39    family probably_close year. almost certain cha...\n",
      "41    unfortunately not_choice dimsum mississauga di...\n",
      "Name: sentiment_text, dtype: object\n",
      "3     1\n",
      "14    3\n",
      "25    1\n",
      "39    3\n",
      "41    3\n",
      "Name: review_stars, dtype: int64\n",
      "CPU times: user 718 ms, sys: 99.2 ms, total: 818 ms\n",
      "Wall time: 829 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CLASSIFICATION\n",
    "df_classes = df[(df['review_stars'] == 1) | (df['review_stars'] == 3) | (df['review_stars'] == 5)]\n",
    "df_classes = df_classes[(df_classes['useful'] == 1)]\n",
    "df_classes.head()\n",
    "print(df_classes.shape)\n",
    "\n",
    "# Seperate the data set into X and Y for prediction\n",
    "x = df_classes['sentiment_text']\n",
    "y = df_classes['review_stars']\n",
    "print(x.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horrible_service tonight boyfriend because pass couple time want try. bok choy_chicken fry rice lemon chicken. food chicken hard_look old like refried. complain server not_acknowledge complaint. leave tell server tell leave offering provide new. finally_woman server offer new_agree old. minute rice bok_choy time bring not_hungry consider not_want eat chicken rice cold exception sweet old_lady serve rest server rude server table check bill. much_tip couple leave. hear mention tip look bill throw angry. disgusting_will not_return.\n",
      "815553\n",
      "  (0, 30547)\t1\n",
      "  (0, 65563)\t1\n",
      "  (0, 73009)\t2\n",
      "  (0, 79829)\t1\n",
      "  (0, 79835)\t1\n",
      "  (0, 83080)\t1\n",
      "  (0, 85776)\t1\n",
      "  (0, 108636)\t1\n",
      "  (0, 111728)\t3\n",
      "  (0, 116277)\t1\n",
      "  (0, 127157)\t1\n",
      "  (0, 132886)\t1\n",
      "  (0, 132899)\t1\n",
      "  (0, 138959)\t1\n",
      "  (0, 148199)\t2\n",
      "  (0, 191543)\t1\n",
      "  (0, 208031)\t1\n",
      "  (0, 228138)\t1\n",
      "  (0, 255877)\t1\n",
      "  (0, 264997)\t1\n",
      "  (0, 281277)\t1\n",
      "  (0, 323597)\t1\n",
      "  (0, 327572)\t1\n",
      "  (0, 341484)\t1\n",
      "  (0, 401546)\t3\n",
      "  :\t:\n",
      "  (0, 484855)\t1\n",
      "  (0, 498489)\t1\n",
      "  (0, 504806)\t1\n",
      "  (0, 509454)\t1\n",
      "  (0, 512640)\t1\n",
      "  (0, 519368)\t1\n",
      "  (0, 519382)\t1\n",
      "  (0, 522140)\t2\n",
      "  (0, 523295)\t1\n",
      "  (0, 545670)\t1\n",
      "  (0, 588320)\t1\n",
      "  (0, 608894)\t1\n",
      "  (0, 616038)\t1\n",
      "  (0, 618405)\t3\n",
      "  (0, 628646)\t1\n",
      "  (0, 649064)\t1\n",
      "  (0, 649153)\t5\n",
      "  (0, 717482)\t1\n",
      "  (0, 720589)\t1\n",
      "  (0, 727828)\t2\n",
      "  (0, 735807)\t1\n",
      "  (0, 736952)\t2\n",
      "  (0, 738357)\t1\n",
      "  (0, 751289)\t1\n",
      "  (0, 788957)\t1\n",
      "CPU times: user 28.8 s, sys: 527 ms, total: 29.3 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r0 = x[3]\n",
    "print(r0)\n",
    "vocab = CountVectorizer(analyzer=text_process,stop_words=stopwords).fit(x)\n",
    "print(len(vocab.vocabulary_))\n",
    "vocab0 = vocab.transform([r0])\n",
    "print(vocab0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization of the whole review set and and checking the sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sparse matrix: (473700, 815553)\n",
      "Non-Zero occurences: 14728803\n",
      "Density of the matrix: 0.003812517792208764\n",
      "CPU times: user 25.7 s, sys: 140 ms, total: 25.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = vocab.transform(x)\n",
    "#Shape of the matrix:\n",
    "print(\"Shape of the sparse matrix: {}\".format(x.shape))\n",
    "#Non-zero occurences:\n",
    "print(\"Non-Zero occurences: {}\".format(x.nnz))\n",
    "\n",
    "# DENSITY OF THE MATRIX\n",
    "density = (x.nnz / (x.shape[0] * x.shape[1])) * 100\n",
    "print(\"Density of the matrix: {}\".format(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data set into training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_pred, classifier_name):\n",
    "    print(\"Confusion Matrix for {}:\".format(classifier_name))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['1-Star', '3-Star', '5-Star']))\n",
    "    print(\"\\nScore: {}\".format(round(accuracy_score(y_true, y_pred)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[13316  2932   497]\n",
      " [ 2287 13353  5010]\n",
      " [  624  2262 54459]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      1-Star       0.82      0.80      0.81     16745\n",
      "      3-Star       0.72      0.65      0.68     20650\n",
      "      5-Star       0.91      0.95      0.93     57345\n",
      "\n",
      "    accuracy                           0.86     94740\n",
      "   macro avg       0.82      0.80      0.81     94740\n",
      "weighted avg       0.85      0.86      0.85     94740\n",
      "\n",
      "\n",
      "Score: 85.63\n",
      "CPU times: user 489 ms, sys: 91.8 ms, total: 581 ms\n",
      "Wall time: 593 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print_results(y_test, predmnb, \"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0 == 1:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rmfr = RandomForestClassifier()\n",
    "    rmfr.fit(x_train, y_train)\n",
    "    p = rmfr.predict(x_test)\n",
    "    print_results(y_test, p, \"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0 == 1:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(x_train,y_train)\n",
    "    p = dt.predict(x_test)\n",
    "    print_results(y_test, p, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0 == 1:\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(random_state=101)\n",
    "    svm.fit(x_train,y_train)\n",
    "    p = svm.predict(x_test)\n",
    "    print_results(y_test, p, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0 == 1:\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    knn.fit(x_train,y_train)\n",
    "    p = knn.predict(x_test)\n",
    "    print_results(y_test, p, \"kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0 == 1:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    mlp = MLPClassifier()\n",
    "    mlp.fit(x_train,y_train)\n",
    "    p = mlp.predict(x_test)\n",
    "    print_results(y_test, p, \"Multilayer Perceptron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekday_morning avoid weekend crowd definitely_enjoy experience food bunch_staple. lotus leaf_wrap sausage. sticky_rice preserve egg congee. egg_yolk bun. pretty_bomb. employee walk cart dim_sum. super cantonese_style item cart menu service super friendly funny_staff. willing_explain despite language_barrier environment bit outdated_lobby washroom particularly sketchy overall_will return tell weekend more_variety dim_sum.\n",
      "\n",
      "Actual Rating: 4\n",
      "Predicted Rating: 3\n"
     ]
    }
   ],
   "source": [
    "item = 11\n",
    "pr = df['sentiment_text'][item]\n",
    "print(pr)\n",
    "print(\"\\nActual Rating: {}\".format(df['review_stars'][item]))\n",
    "pr_t = vocab.transform([pr])\n",
    "print(\"Predicted Rating: {}\".format(mnb.predict(pr_t)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 10.7 s, total: 22.1 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(cleaned_reviews_file, 'wb') as file:\n",
    "    pickle.dump(df, file)\n",
    "\n",
    "with open(df_classes_file, 'wb') as file:\n",
    "    pickle.dump(df_classes, file)\n",
    "\n",
    "with open(vocab_file, 'wb') as file:\n",
    "    pickle.dump(vocab, file)\n",
    "\n",
    "with open(transformed_sentiment_file, 'wb') as file:\n",
    "    pickle.dump(x, file)\n",
    "\n",
    "with open(classifier_file, 'wb') as file:\n",
    "    pickle.dump(mnb, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
